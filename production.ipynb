{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import heapq\n",
    "import jellyfish\n",
    "import sys\n",
    "import datetime as datetime\n",
    "import string\n",
    "from gensim import *\n",
    "import recordlinkage as rl\n",
    "import sklearn\n",
    "from recordlinkage.standardise import clean\n",
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.validation import NotFittedError\n",
    "from sklearn.ensemble import *\n",
    "from xgboost import XGBClassifier\n",
    "import math, time\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import multiprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "def jarowinkler_similarity(s1, s2):\n",
    "    \n",
    "    conc = pd.concat([s1, s2], axis=1, ignore_index=True)\n",
    "    def jaro_winkler_apply(x):\n",
    "        try:\n",
    "            return jellyfish.jaro_winkler(x[0], x[1])\n",
    "        except Exception as err:\n",
    "            if pd.isnull(x[0]) or pd.isnull(x[1]):\n",
    "                return np.nan\n",
    "            else:\n",
    "                raise err\n",
    "    return conc.apply(jaro_winkler_apply, axis=1)\n",
    "\n",
    "def postcode_block(data_one, data_two, block_key):\n",
    "    \n",
    "    # create candidate record pairs\n",
    "    pcl_blocks = rl.Pairs(data_one, data_two)\n",
    "    # block on postcode\n",
    "    pairs = pcl_blocks.block(left_on=block_key, right_on=block_key)\n",
    "    parts = []\n",
    "    start_slice = 0\n",
    "    while start_slice <= len(pairs):\n",
    "        # Set the end of the slice\n",
    "        end_slice = start_slice + 1\n",
    "        # Slice the MultiIndex \n",
    "        m_ind = pairs[start_slice:end_slice]\n",
    "        ind = m_ind.get_level_values(0)\n",
    "        # The actual indexing\n",
    "        index_result = data_one.loc[ind]\n",
    "        # Append to list named parts\n",
    "        parts.append(index_result)\n",
    "        # Set new slice start\n",
    "        start_slice = end_slice  \n",
    "    data_one_rl = pd.concat(parts, axis=0, copy=False)\n",
    "    data_one_rl.index = pairs\n",
    "    return data_one_rl\n",
    "\n",
    "def all_addresses(training=False, word2vec=False):\n",
    "    \n",
    "    def null_check(string):\n",
    "        if pd.notnull(string) and string[0].isdigit():\n",
    "            return 'unit ' + str(string)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    headers = ['id','bic', 'ndr', 'ba', 'desc_code', 'desc', 'uarn', 'prop_id', 'firm_name', 'num', 'street', 'town', 'post_dist', 'county', 'PostCode', 'eff_date', 'comp_ind', 'rateable_val', 'appeal_code', 'assess_ref', 'alt_date', 'scat_code', 'sub_lev3', 'sub_lev2', 'sub_lev1', 'case_no', 'curr_from', 'curr_to']\n",
    "    \n",
    "    ldc_potential_fields = ['b_NameFull','ad_Building_Unit','ad_Building','ad_Building_Floor', 'ad_shop_centre','ad_StreetNo','ad_StreetNo2','ad_Street','ad_City','region', 'ad_Zip']\n",
    "    voa_potential_fields = ['num', 'street', 'town', 'post_dist', 'county', 'PostCode']\n",
    "\n",
    "    # use training data to test string matching\n",
    "    if training == True:\n",
    "        \n",
    "        voa_2010 = pd.read_csv('./data/voa2010.csv', \n",
    "                 na_values='', \n",
    "                 sep='\\r', \n",
    "                 delimiter = '*', \n",
    "                 encoding='latin_1', \n",
    "                 names=headers, \n",
    "                 index_col=False)\n",
    "\n",
    "        # lookup tables\n",
    "        replacements = {'BEDS':'bedfordshire',\n",
    "                        'HERTS':'hertfordshire',\n",
    "                        'WILTS':'wiltshire',\n",
    "                        'BUCKS':'buckinghamshire',\n",
    "                        'OXON':'oxfordshire',\n",
    "                        'BERKS':'berkshire',\n",
    "                        'GLOS':'gloucestershire',\n",
    "                        'CAMBS':'cambridgeshire',\n",
    "                        'LINCS':'lincolnshire',\n",
    "                        'HANTS':'hampshire',\n",
    "                        'NOTTS':'nottinghamshire',\n",
    "                        'LANCS':'lancashire',\n",
    "                        'STAFFS':'staffordshire',\n",
    "                        'LEICS':'leicestershire',\n",
    "                        'WORCS':'worcestershire',\n",
    "                        'DEVON':'devonshire',\n",
    "                        'MIDDX':'middlesex',\n",
    "                        'NORTHANTS':'northamptonshire',\n",
    "                        'NORTHD':'northumberland',\n",
    "                        'CO DURHAM':'county durham'\n",
    "                       }\n",
    "\n",
    "        voa_2010['county'] = voa_2010['county'].replace(replacements)\n",
    "\n",
    "        \n",
    "        # load data and normalize to VOA to assist comparison\n",
    "        ldc_df = pd.read_csv('./data/ldc_data.csv', dtype=str)\n",
    "        ldc_df['ad_StreetNo'] = ldc_df[['ad_StreetNo','ad_StreetLetter']].fillna('').apply(lambda x: ''.join(x), axis=1)\n",
    "        ldc_df['ad_StreetNo2'] = ldc_df[['ad_StreetNo2','ad_StreetLetter2']].fillna('').apply(lambda x: ''.join(x), axis=1)\n",
    "        ldc_df[['ad_StreetNo', 'ad_StreetNo2']] = ldc_df[['ad_StreetNo', 'ad_StreetNo2']].replace('', np.nan)\n",
    "\n",
    "        # if unit column starts with a number, append unit prefix \n",
    "        ldc_df['ad_Building_Unit'] = ldc_df.ad_Building_Unit.apply(lambda x: null_check(x))\n",
    "        \n",
    "        # concatenate street numbers where there is secodnary street number\n",
    "        ldc_df['ad_StreetNo'] = ldc_df['ad_StreetNo'].astype(str)\n",
    "\n",
    "        # Create a mask of those addresses having an additional street number.\n",
    "        mask = ldc_df.loc[ldc_df['ad_StreetNo2'].notnull()]\n",
    "\n",
    "        # Use the mask to append the additional street number.\n",
    "        ldc_df.loc[mask.index, 'ad_StreetNo'] += '-' + ldc_df.loc[mask.index, 'ad_StreetNo2'].astype(str)\n",
    "\n",
    "        # Set the additional  number to NaN.\n",
    "        ldc_df.loc[mask.index, 'ad_StreetNo2'] = np.nan\n",
    "\n",
    "        # keep ldc records with UARN key\n",
    "        ldc_uarn = ldc_df[pd.notnull(ldc_df['V_UARN'])]\n",
    "\n",
    "        ldc_uarn.V_UARN = ldc_uarn.V_UARN.astype(str)\n",
    "        voa_2010.uarn = voa_2010.uarn.astype(str)\n",
    "\n",
    "        # merge to create training data\n",
    "        training = pd.merge(voa_2010, ldc_uarn, how='inner', left_on='uarn', right_on='V_UARN')\n",
    "\n",
    "        # create validation set\n",
    "        uarns = [str(i) for i in training.uarn.values.tolist()]\n",
    "        voa_validation = voa_2010[voa_2010['uarn'].apply(str).isin(uarns)]\n",
    "        ldc_validation = ldc_df[ldc_df['V_UARN'].isin(training['V_UARN'].values.tolist())]\n",
    "        \n",
    "        if word2vec == False:\n",
    "            voa_validation = pd.DataFrame({'uarn': voa_validation['uarn'],'address': (voa_validation.apply(lambda r: ', '.join([str(r[c]).strip().replace('.0','').lower() for c in voa_potential_fields if not pd.isnull(r[c])]),axis=1)),'postcode':voa_validation['PostCode']})\n",
    "            ldc_validation = pd.DataFrame({'uarn': ldc_validation['V_UARN'] ,'address': (ldc_validation.apply(lambda r: ', '.join([str(r[c]).strip().replace('.0','').lower() for c in ldc_potential_fields if not pd.isnull(r[c])]),axis=1)),'postcode':ldc_validation['ad_Zip']})\n",
    "        elif word2vec == True:\n",
    "            voa_validation = pd.DataFrame({'uarn': voa_validation['uarn'],'address': (voa_validation.apply(lambda r: ' '.join([str(r[c]).strip().replace('.0','').lower() for c in voa_potential_fields if not pd.isnull(r[c])]),axis=1)),'postcode':voa_validation['PostCode']})\n",
    "            ldc_validation = pd.DataFrame({'uarn': ldc_validation['V_UARN'] ,'address': (ldc_validation.apply(lambda r: ' '.join([str(r[c]).strip().replace('.0','').lower() for c in ldc_potential_fields if not pd.isnull(r[c])]),axis=1)),'postcode':ldc_validation['ad_Zip']})\n",
    "        \n",
    "        \n",
    "        all_address = voa_validation['address'].append(ldc_validation['address'],ignore_index=True)\n",
    "\n",
    "        return [ldc_validation, voa_validation, all_address]\n",
    "    \n",
    "    else:\n",
    "        voa_data = pd.read_csv('./data/list_entries.csv', \n",
    "                         na_values='', \n",
    "                         sep='\\r', \n",
    "                         delimiter = '*', \n",
    "                         encoding='latin_1', \n",
    "                         names=headers, \n",
    "                         index_col=False)\n",
    "        \n",
    "        ldc_data = pd.read_csv('./data/ldc_data.csv',header=0)\n",
    "\n",
    "        # ldc_addresses = ldc_data.apply(lambda r: ' '.join([str(r[c]).strip().replace('.0','').lower() for c in ldc_potential_fields if not pd.isnull(r[c])]),axis=1)\n",
    "        ldc_addresses = pd.DataFrame({'address': (ldc_data.apply(lambda r: ' '.join([str(r[c]).strip().replace('.0','').lower() for c in ldc_potential_fields if not pd.isnull(r[c])]),axis=1)),'postcode':ldc_data['ad_Zip']})\n",
    "        voa_addresses = pd.DataFrame({'address':(voa_data['prop_id']+ ' ' + voa_data['PostCode']).astype(str).map(lambda x:x.replace(',','').lower()).fillna(''), 'postcode':voa_data['PostCode']})\n",
    "\n",
    "        all_address = voa_addresses['address'].append(ldc_addresses['address'],ignore_index=True)\n",
    "\n",
    "        return [ldc_addresses, voa_addresses, all_address]\n",
    "    \n",
    "def matching(groups, propensity_scores):\n",
    "    \n",
    "    # code groups as 0 and 1\n",
    "    N = len(y)\n",
    "    N1 = int(y.sum())\n",
    "    N2 = N - N1\n",
    "    g1, g2 = propensity_scores[0:N1], propensity_scores[N1:]\n",
    "    morder = np.random.permutation(N1)\n",
    "    matches = pd.Series(np.empty(N1))\n",
    "    matches[:] = np.NAN\n",
    "    if N1 > N2:\n",
    "        N1, N2, g1, g2 = N2, N1, g2, g1 \n",
    "    for m in morder:\n",
    "        dist = abs(g1[m] - g2)\n",
    "        matches[m] = dist.argmin()\n",
    "        g2 = g2.drop(matches[m])\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def tfidf_similarity(s1, s2):\n",
    "    \n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    tfidf = TfidfVectorizer(analyzer = 'word', min_df=1)\n",
    "\n",
    "    tfidf.fit(all_address_train)\n",
    "    tfidf_lookup = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "\n",
    "    conc = pd.concat([s1, s2], axis=1, ignore_index=True)\n",
    "    \n",
    "    def tfidf_apply(x):\n",
    "        try:\n",
    "            a1_tokens = x[0].split()\n",
    "            a2_tokens = x[1].split()\n",
    "            \n",
    "            # get intersection tokens\n",
    "            intersection = getIntersection(a1_tokens, a2_tokens)\n",
    "\n",
    "            if intersection:\n",
    "                # calculate similarity score based on rareness of tokens\n",
    "                similarity = computeSimilarity(x[0], x[1], intersection)\n",
    "            else:\n",
    "                similarity = 0\n",
    "            return similarity\n",
    "        except Exception as err:\n",
    "            if pd.isnull(x[0]) or pd.isnull(x[1]):\n",
    "                return np.nan\n",
    "            else:\n",
    "                raise err\n",
    "    \n",
    "    def getIntersection(s1,s2):\n",
    "        return set(s1).intersection(s2)\n",
    "\n",
    "    def computeUniqueness(s, isToken = True):\n",
    "        if not isToken:\n",
    "            if s in lookup_uniqueness:\n",
    "                return lookup_uniqueness[s]\n",
    "            tokens = s.split()\n",
    "        else:\n",
    "            tokens = s\n",
    "        score = 1\n",
    "        for t in tokens:\n",
    "            if t in tfidf_lookup:\n",
    "                score += tfidf_lookup[t]\n",
    "        if not isToken:\n",
    "            lookup_uniqueness[s] = score\n",
    "        return score\n",
    "\n",
    "    def computeSimilarity(s1,s2,intersection):\n",
    "        return computeUniqueness(intersection)/((computeUniqueness(s1,isToken=False)*computeUniqueness(s2,isToken=False))**0.5)\n",
    "\n",
    "    return conc.apply(tfidf_apply, axis=1)\n",
    "        \n",
    "def reduction_ratio(n, x):\n",
    "\n",
    "    def max_pairs(shape):\n",
    "\n",
    "        if not isinstance(shape, (tuple, list)):\n",
    "            n = _max_pairs_deduplication(_get_len(shape))\n",
    "\n",
    "        elif (isinstance(shape, (tuple, list)) and len(shape) == 1):\n",
    "            n = _max_pairs_deduplication(_get_len(shape[0]))\n",
    "\n",
    "        else:\n",
    "            n = _max_pairs_linkage([_get_len(xi) for xi in shape])\n",
    "\n",
    "        return n\n",
    "\n",
    "    n_max = max_pairs(x)\n",
    "\n",
    "    if isinstance(n, pandas.MultiIndex):\n",
    "        n = len(n)\n",
    "\n",
    "    if n > n_max:\n",
    "        raise ValueError(\"n has to be smaller of equal n_max\")\n",
    "\n",
    "\n",
    "    return 1 - n / n_max\n",
    "\n",
    "def specificity(confusion_matrix):\n",
    "\n",
    "    v = confusion_matrix[1, 1] \\\n",
    "        / (confusion_matrix[1, 1] + confusion_matrix[1, 0])\n",
    "\n",
    "    return float(v)\n",
    "\n",
    "def false_positive_rate(confusion_matrix):\n",
    "\n",
    "    v = confusion_matrix[1, 0] \\\n",
    "        / (confusion_matrix[1, 1] + confusion_matrix[1, 0])\n",
    "    \n",
    "    return float(v)\n",
    "\n",
    "def precision(confusion_matrix):\n",
    "\n",
    "    v = confusion_matrix[0, 0] \\\n",
    "        / (confusion_matrix[0, 0] + confusion_matrix[1, 0])\n",
    "\n",
    "    return float(v)\n",
    "\n",
    "\n",
    "def recall(confusion_matrix):\n",
    "\n",
    "\n",
    "    v = confusion_matrix[0, 0] \\\n",
    "        / (confusion_matrix[0, 0] + confusion_matrix[0, 1])\n",
    "\n",
    "    return float(v)\n",
    "\n",
    "def fscore(confusion_matrix):\n",
    "\n",
    "    prec = precision(confusion_matrix)\n",
    "    rec = recall(confusion_matrix)\n",
    "\n",
    "    return float(2 * prec * rec / (prec + rec))\n",
    "\n",
    "def true_positives(true_match_index, matches_index):\n",
    "\n",
    "    return len(true_match_index & matches_index)\n",
    "\n",
    "\n",
    "def true_negatives(true_match_index, matches_index, n_pairs):\n",
    "\n",
    "    if not isinstance(n_pairs, (int, float)):\n",
    "        n_pairs = len(n_pairs)\n",
    "\n",
    "    return int(n_pairs) - len(true_match_index | matches_index)\n",
    "\n",
    "\n",
    "def false_positives(true_match_index, matches_index):\n",
    "\n",
    "    # The classified matches without the true matches.\n",
    "    return len(matches_index.difference(true_match_index))\n",
    "\n",
    "\n",
    "def false_negatives(true_match_index, matches_index):\n",
    "\n",
    "    return len(true_match_index.difference(matches_index))\n",
    "\n",
    "def confusion_matrix(true_match_index, matches_index, n_pairs):\n",
    "    \"\"\"Compute the confusion matrix.\n",
    "    The confusion matrix is of the following\n",
    "    form:\n",
    "    +---------------------+-----------------------+----------------------+\n",
    "    |                     |  Predicted Positive   | Predicted Negatives  |\n",
    "    +=====================+=======================+======================+\n",
    "    | **True Positive**   | True Positives (TP)   | False Negatives (FN) |\n",
    "    +---------------------+-----------------------+----------------------+\n",
    "    | **True Negative**   | False Positives (FP)  | True Negatives (TN)  |\n",
    "    +---------------------+-----------------------+----------------------+\n",
    "    \"\"\"\n",
    "\n",
    "    # True positives\n",
    "    tp = true_positives(true_match_index, matches_index)\n",
    "\n",
    "    # True negatives\n",
    "    tn = true_negatives(true_match_index, matches_index, n_pairs)\n",
    "\n",
    "    # False positives\n",
    "    fp = false_positives(true_match_index, matches_index)\n",
    "\n",
    "    # False negatives\n",
    "    fn = false_negatives(true_match_index, matches_index)\n",
    "\n",
    "    return np.array([[tp, fn], [fp, tn]])\n",
    "\n",
    "class LearningError(Exception):\n",
    "    \"\"\"Learning error\"\"\"\n",
    "\n",
    "class Classifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.classifier = None\n",
    "\n",
    "    def learn(self, comparison_vectors, match_index, return_type='index'):\n",
    "\n",
    "        if isinstance(match_index, (pandas.MultiIndex, pandas.Index)):\n",
    "\n",
    "            # The match_index variable is of type MultiIndex\n",
    "            train_series = pandas.Series(False, index=comparison_vectors.index)\n",
    "\n",
    "            try:\n",
    "                train_series.loc[match_index & comparison_vectors.index] = True\n",
    "\n",
    "            except pandas.IndexError as err:\n",
    "\n",
    "                # The are no matches. So training is not possible.\n",
    "                if len(match_index & comparison_vectors.index) == 0:\n",
    "                    raise LearningError(\n",
    "                        \"both matches and non-matches needed in the\" +\n",
    "                        \"trainingsdata, only non-matches found\"\n",
    "                    )\n",
    "                else:\n",
    "                    raise err\n",
    "\n",
    "        self.classifier.fit(\n",
    "            comparison_vectors.as_matrix(),\n",
    "            numpy.array(train_series)\n",
    "        )\n",
    "                                \n",
    "        return self.predict(comparison_vectors, return_type)\n",
    "    \n",
    "    def predict_proba(self, comparison_vectors):\n",
    "        \n",
    "        y_pred = self.classifier.predict_proba(comparison_vectors)\n",
    "    \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def predict(self, comparison_vectors, return_type='index'):\n",
    "\n",
    "        try:\n",
    "            prediction = self.classifier.predict(\n",
    "                comparison_vectors.as_matrix())\n",
    "        except NotFittedError:\n",
    "            raise NotFittedError(\n",
    "                \"This {} is not fitted yet. Call 'learn' with appropriate \"\n",
    "                \"arguments before using this method.\".format(\n",
    "                    type(self).__name__\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return self._return_result(prediction, return_type, comparison_vectors)\n",
    "    \n",
    "    def _return_result(\n",
    "        self, result, return_type='index', comparison_vectors=None\n",
    "    ):\n",
    "\n",
    "\n",
    "        if type(result) != numpy.ndarray:\n",
    "            raise ValueError(\"numpy.ndarray expected.\")\n",
    "\n",
    "        # return the pandas.MultiIndex\n",
    "        if return_type == 'index':\n",
    "            return comparison_vectors.index[result.astype(bool)]\n",
    "\n",
    "        # return a pandas.Series\n",
    "        elif return_type == 'series':\n",
    "            return pandas.Series(\n",
    "                result,\n",
    "                index=comparison_vectors.index,\n",
    "                name='classification')\n",
    "\n",
    "        # return a numpy.ndarray\n",
    "        elif return_type == 'array':\n",
    "            return result\n",
    "\n",
    "        # return_type not known\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"return_type {} unknown. Choose 'index', 'series' or \"\n",
    "                \"'array'\".format(return_type))\n",
    "\n",
    "from sklearn import cluster, linear_model\n",
    "\n",
    "class RandomForestClassifierRl(Classifier):\n",
    "\n",
    "    def __init__(self, trees, features, *args, **kwargs):\n",
    "        super(self.__class__, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # initialise with model params\n",
    "        self.trees = trees\n",
    "        self.max_feature = features\n",
    "\n",
    "        self.classifier = RandomForestClassifier(n_estimators=trees, max_features=features)\n",
    "        \n",
    "    def feature_importance(self):\n",
    "\n",
    "        importances = self.classifier.feature_importances_\n",
    "\n",
    "        return importances\n",
    "    \n",
    "    def estimator(self):\n",
    "        \n",
    "        est = self.classifier.estimators_\n",
    "\n",
    "        return est\n",
    "\n",
    "class LogisticRegressionClassifierRl(Classifier):\n",
    "\n",
    "    def __init__(self, coefficients=None, intercept=None):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "        self.classifier = linear_model.LogisticRegression()\n",
    "\n",
    "        self.coefficients = coefficients\n",
    "        self.intercept = intercept\n",
    "\n",
    "        self.classifier.classes_ = numpy.array([False, True])\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return {\n",
    "            'coefficients': self.coefficients,\n",
    "            'intercept': self.intercept\n",
    "        }\n",
    "\n",
    "    @params.setter\n",
    "    def params(self, value):\n",
    "\n",
    "        if not isinstance(value, dict):\n",
    "            raise ValueError(\"parameters are of wrong type\")\n",
    "\n",
    "        self.coefficients = value['coefficients']\n",
    "        self.interceptall_addresses = value['intercept']\n",
    "\n",
    "    @property\n",
    "    def coefficients(self):\n",
    "        # Return the coefficients if available\n",
    "        try:\n",
    "            return list(self.classifier.coef_[0])\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @coefficients.setter\n",
    "    def coefficients(self, value):\n",
    "\n",
    "        if value is not None:\n",
    "\n",
    "            # Check if array if numpy array\n",
    "            if type(value) is not numpy.ndarray:\n",
    "                value = numpy.array(value)\n",
    "\n",
    "            self.classifier.coef_ = value.reshape((1, len(value)))\n",
    "\n",
    "    @property\n",
    "    def intercept(self):\n",
    "\n",
    "        try:\n",
    "            return float(self.classifier.intercept_[0])\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @intercept.setter\n",
    "    def intercept(self, value):\n",
    "\n",
    "        if value is not None:\n",
    "\n",
    "            if not isinstance(value, (list)):\n",
    "                value = numpy.array(value)\n",
    "            else:\n",
    "                value = numpy.array([value])\n",
    "\n",
    "            self.classifier.intercept_ = value\n",
    "\n",
    "        # value is None\n",
    "        elif value is None:\n",
    "            try:\n",
    "                del self.classifier.intercept_\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        else:\n",
    "            raise ValueError('incorrect type')\n",
    "\n",
    "class XGBClassifierRl(Classifier):\n",
    "\n",
    "    def __init__(self, n_boosted_trees,*args, **kwargs):\n",
    "        super(self.__class__, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.n_boosted_trees = n_boosted_trees\n",
    "        \n",
    "        # initialise with model params\n",
    "        self.classifier = XGBClassifier(n_estimators=n_boosted_trees)\n",
    "        \n",
    "def avg_feature_vector(words, weight_avg=False):\n",
    "\n",
    "    featureVec = np.zeros((100,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    # list containing names of words in the vocabulary\n",
    "    index2word_set = set(paf_w2v.wv.index2word) \n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            \n",
    "            if weight_avg == True:\n",
    "                \n",
    "                if frequency_table[word] == 1:\n",
    "                    tfidf = 1/math.log(1.5)\n",
    "                else:\n",
    "                    tfidf = 1/math.log(frequency_table[word])\n",
    "        \n",
    "            else:\n",
    "                # compute per-document tfidf\n",
    "                tfidf_values = dict(tfidf_model[dictionary.doc2bow(words)])\n",
    "                tfidf = tfidf_values[dictionary.token2id[word]]\n",
    "            \n",
    "            # weight by proportional importance \n",
    "            word_vec = tfidf * paf_w2v[word]\n",
    "                        \n",
    "            featureVec = np.add(featureVec, word_vec)\n",
    "        \n",
    "            nwords = nwords+1\n",
    "        \n",
    "    if(nwords>0):\n",
    "#         featureVec = np.sum(featureVec)\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    \n",
    "    return featureVec\n",
    "    \n",
    "def joblib_loop(data):\n",
    "    return Parallel(n_jobs=20)(delayed(avg_feature_vector)(words=address.split()) for i,address in enumerate(data))\n",
    "\n",
    "def show_confusion_matrix(name, C,class_labels=['Match','Non-match']):\n",
    "    \"\"\"\n",
    "    C: ndarray, shape (2,2) as given by scikit-learn confusion_matrix function\n",
    "    class_labels: list of strings, default simply labels 0 and 1.\n",
    "\n",
    "    Draws confusion matrix with associated metrics.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    assert C.shape == (2,2), \"Confusion matrix should be from binary classification only.\"\n",
    "    \n",
    "    # true negative, false positive, etc...\n",
    "    tp = C[0,0]; fn = C[0,1]; fp = C[1,0]; tn = C[1,1];\n",
    "    \n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax  = fig.add_subplot(111)\n",
    "    ax.imshow(C, interpolation='nearest', cmap=plt.cm.coolwarm)\n",
    "\n",
    "    # Draw the grid boxes\n",
    "    ax.set_xlim(-0.5,2.5)\n",
    "    ax.set_ylim(2.5,-0.5)\n",
    "    ax.plot([-0.5,2.5],[0.5,0.5], '-k', lw=2)\n",
    "    ax.plot([-0.5,2.5],[1.5,1.5], '-k', lw=2)\n",
    "    ax.plot([0.5,0.5],[-0.5,2.5], '-k', lw=2)\n",
    "    ax.plot([1.5,1.5],[-0.5,2.5], '-k', lw=2)\n",
    "\n",
    "    # Set xlabels\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(class_labels + [''])\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.tick_top()\n",
    "    \n",
    "    # These coordinate might require some tinkering. Ditto for y, below.\n",
    "    ax.xaxis.set_label_coords(0.34,1.06)\n",
    "\n",
    "    # Set ylabels\n",
    "    ax.set_yticklabels(class_labels + [''],rotation=90)\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.yaxis.set_label_coords(-0.09,0.65)\n",
    "\n",
    "\n",
    "    # Fill in initial metrics: tp, tn, etc...\n",
    "    ax.text(0,0,\n",
    "            'True Pos: %d\\n(Num Pos: %d)'%(tp,NP),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,1,\n",
    "            'False Pos: %d'%fp,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,0,\n",
    "            'False Neg: %d'%fn,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    ax.text(1,1,\n",
    "            'True Neg: %d\\n(Num Neg: %d)'%(tn,NN),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    # Fill in secondary metrics: accuracy, true pos rate, etc...\n",
    "    ax.text(2,1,\n",
    "            'False Pos Rate: %.5f'%(fp/(tn+fp)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,0,\n",
    "            'True Pos Rate: %.5f'%(tp/(tp+fn)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    prec = precision(C)\n",
    "    rec = recall(C)\n",
    "\n",
    "    ax.text(2,2,\n",
    "            'F1 Score: %.5f'%(float(2 * prec * rec / (prec + rec))),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,2,\n",
    "            'Recall: %.5f'%(tp/(tp+fn)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,2,\n",
    "            'Precision: %.5f'%(tp/(tp+fp)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name, dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "def calc_inbag(n_samples, forest, n_trees):\n",
    "\n",
    "    inbag = np.zeros((n_samples, n_trees))\n",
    "    sample_idx = []\n",
    "    for t_idx in range(n_trees):\n",
    "        sample_idx.append(\n",
    "            _generate_sample_indices(forest.estimator()[t_idx].random_state,\n",
    "                                     n_samples))\n",
    "        inbag[:, t_idx] = np.bincount(sample_idx[-1], minlength=n_samples)\n",
    "    return inbag\n",
    "\n",
    "\n",
    "def _bias_correction(V_IJ, inbag, pred_centered, n_trees):\n",
    "    n_train_samples = inbag.shape[0]\n",
    "    n_var = np.mean(np.square(inbag[0:n_trees]).mean(axis=1).T.view() -\n",
    "                    np.square(inbag[0:n_trees].mean(axis=1)).T.view())\n",
    "    boot_var = np.square(pred_centered).sum(axis=1) / n_trees\n",
    "    bias_correction = n_train_samples * n_var * boot_var / n_trees\n",
    "    V_IJ_unbiased = V_IJ - bias_correction\n",
    "    return V_IJ_unbiased\n",
    "        \n",
    "def random_forest_error(forest, X_train, X_test, n_trees, inbag=None,\n",
    "                        memory_constrained=False, memory_limit=10000):\n",
    "\n",
    "    if inbag is None:\n",
    "        inbag = calc_inbag(X_train.shape[0], forest, n_trees)\n",
    "        \n",
    "    pred = np.array([tree.predict(X_test) for tree in forest.estimator()]).T\n",
    "    pred_mean = np.mean(pred, 0)\n",
    "    pred_centered = pred - pred_mean\n",
    "        \n",
    "    chunk_size = int((memory_limit * 1e6) /(8.0 * X_train.shape[0]))\n",
    "    \n",
    "    chunk_edges = np.arange(0,X_test.shape[0]+chunk_size,chunk_size)\n",
    "    inds = range(X_test.shape[0])\n",
    "    chunks = [inds[chunk_edges[i]:chunk_edges[i+1]] \n",
    "              for i in range(len(chunk_edges)-1)]\n",
    "    print('Number of chunks: %d' % (len(chunks),))\n",
    "    V_IJ = np.concatenate([np.sum((np.dot(inbag-1,\n",
    "                                          pred_centered[chunk].T)/n_trees)**2,0)\n",
    "                           for chunk in chunks])\n",
    "        \n",
    "        \n",
    "        \n",
    "    V_IJ_unbiased = _bias_correction(V_IJ, inbag, pred_centered, n_trees)\n",
    "    \n",
    "    if np.max(inbag) == 1:\n",
    "        variance_inflation = 1 / (1 - np.mean(inbag)) ** 2\n",
    "        V_IJ_unbiased *= variance_inflation\n",
    "\n",
    "    return V_IJ_unbiased\n",
    "    \n",
    "# dict for tfidf storage\n",
    "lookup_uniqueness = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Supervised Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mRandom Forests Results: \u001b[0m\n",
      "\n",
      "[[ 27630    156]\n",
      " [   158 124742]]\n",
      "\n",
      "Recall:    0.9943856618440942\n",
      "Precision: 0.9943140924139916\n",
      "F1 Score:  0.9943498758412207\n",
      "Specificity:  0.9987349879903923\n",
      "False Positive Rate:  0.0012650120096076862\n",
      "\n",
      "1. tfidf_score  (8) (0.470417)\n",
      "2. city_jaro  (1) (0.248009)\n",
      "3. road_jaro  (0) (0.166458)\n",
      "4. house_number_jaro  (3) (0.109326)\n",
      "5. house_jaro  (2) (0.005604)\n",
      "6. suburb_jaro  (6) (0.000130)\n",
      "7. unit_jaro  (7) (0.000052)\n",
      "8. state_jaro  (5) (0.000003)\n",
      "9. level_jaro  (4) (0.000002)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ef7b63710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mXGBoost Results: \u001b[0m\n",
      "\n",
      "[[ 27659    127]\n",
      " [   158 124742]]\n",
      "\n",
      "Recall:    0.9954293529115382\n",
      "Precision: 0.9943200201315742\n",
      "F1 Score:  0.9948743772818013\n",
      "Specificity:  0.9987349879903923\n",
      "False Positive Rate:  0.0012650120096076862\n",
      "\n",
      "\u001b[32mLogistic Regression Results:\u001b[0m\n",
      "\n",
      "[[ 27496    290]\n",
      " [   206 124694]]\n",
      "\n",
      "Recall:    0.9895630893255596\n",
      "Precision: 0.9925637138112772\n",
      "F1 Score:  0.9910611303344867\n",
      "Specificity:  0.9983506805444355\n",
      "False Positive Rate:  0.0016493194555644516\n",
      "\n",
      "\n",
      "\u001b[32mLogisticRegressionClassifierRl\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmKAsURhjjAnKEoUxxpigLFEYY4wJ6v8B4J3P9LV3rEsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ef7b36f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mRandomForestClassifierRl\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ef7c2db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load training data\n",
    "ldc_training, voa_training, all_address_train = all_addresses(training=True, word2vec=False)\n",
    "\n",
    "from postal.parser import parse_address\n",
    "\n",
    "# parse address for each cleaned voa record\n",
    "ldc_training_lib = [parse_address(i) for i in ldc_training.address]\n",
    "voa_training_lib = [parse_address(i) for i in voa_training.address]\n",
    "\n",
    "# build df from list of list of tuples\n",
    "ldc_training_lib = pd.DataFrame.from_records([{k: v for v, k in row} for row in ldc_training_lib]).add_suffix('_ldc')\n",
    "voa_training_lib = pd.DataFrame.from_records([{k: v for v, k in row} for row in voa_training_lib]).add_suffix('_voa')\n",
    "\n",
    "# get libpostal segmentation for both address sets then join by uarn key\n",
    "ldc_training_merge = ldc_training.reset_index()\n",
    "ldc_training_merge = pd.merge(ldc_training_merge, ldc_training_lib, left_index=True, right_index=True)\n",
    "\n",
    "voa_training_merge = voa_training.reset_index(drop=True)\n",
    "voa_training_merge = pd.merge(voa_training_merge, voa_training_lib, left_index=True, right_index=True)\n",
    "\n",
    "# merge training data on uarn key\n",
    "comp_vec = pd.merge(ldc_training_merge, voa_training_merge, left_on='uarn', right_on='uarn')\n",
    "\n",
    "# use left to index LDC and UARN to index VOA\n",
    "comp_vec.set_index([comp_vec.index, 'uarn'], inplace=True)\n",
    "\n",
    "# column labels to list\n",
    "cols = list(comp_vec.columns)\n",
    "\n",
    "######### DATA AUGMENTATION STEP ###########\n",
    "\n",
    "shuffle_ldc = comp_vec[cols[0:19]] # voa columns\n",
    "shuffle_voa = comp_vec[cols[19:]] # ldc columns\n",
    "\n",
    "shuffle_ldc = shuffle_ldc.reset_index(drop=True)\n",
    "shuffle_voa = shuffle_voa.reset_index(drop=True)\n",
    "\n",
    "# create REAL index to reference back\n",
    "shuffle_ldc.insert(0, 'ldc_index', range(221484, 221484 + len(shuffle_ldc)))\n",
    "shuffle_voa.insert(0, 'voa_index', range(332226, 332226 + len(shuffle_voa)))\n",
    "\n",
    "# shuffle indexes \n",
    "ldc_shuffle = shuffle_ldc.reindex(np.random.permutation(shuffle_ldc.index))\n",
    "voa_shuffle = shuffle_voa.reindex(np.random.permutation(shuffle_voa.index))\n",
    "\n",
    "# sample with replacement here\n",
    "ldc_shuffle = ldc_shuffle.sample(500000, replace=True)\n",
    "voa_shuffle = voa_shuffle.sample(500000, replace=True)\n",
    "\n",
    "# create FAKE index to link\n",
    "ldc_shuffle['new_ind'] = list(range(len(voa_shuffle)))\n",
    "voa_shuffle['new_ind'] = list(range(len(voa_shuffle)))\n",
    "\n",
    "voa_shuffle = voa_shuffle.set_index(['new_ind'])\n",
    "ldc_shuffle = ldc_shuffle.set_index(['new_ind'])\n",
    "\n",
    "# join shuffled indexes for synthetic non-matches\n",
    "non_matches = voa_shuffle.join(ldc_shuffle)\n",
    "non_matches = non_matches.reset_index(drop=True)\n",
    "\n",
    "# set indexes as same to ground truth data\n",
    "non_matches.set_index(['voa_index', 'ldc_index'], inplace=True)\n",
    "\n",
    "comp_vec_train = comp_vec.append(non_matches)\n",
    "\n",
    "########### END OF DATA AUGMENTATION ####################\n",
    "\n",
    "# build feature columns\n",
    "comp_vec_train['category_jaro'] = jarowinkler_similarity(comp_vec_train.category_ldc, comp_vec_train.category_voa)\n",
    "comp_vec_train['road_jaro'] = jarowinkler_similarity(comp_vec_train.road_ldc, comp_vec_train.road_voa)\n",
    "comp_vec_train['city_jaro'] = jarowinkler_similarity(comp_vec_train.city_ldc, comp_vec_train.city_voa)\n",
    "comp_vec_train['city_district_jaro'] = jarowinkler_similarity(comp_vec_train.city_district_ldc, comp_vec_train.city_district_voa)\n",
    "comp_vec_train['house_jaro'] = jarowinkler_similarity(comp_vec_train.house_ldc, comp_vec_train.house_voa)\n",
    "comp_vec_train['house_number_jaro'] = jarowinkler_similarity(comp_vec_train.house_number_ldc, comp_vec_train.house_number_voa)\n",
    "comp_vec_train['level_jaro'] = jarowinkler_similarity(comp_vec_train.level_ldc, comp_vec_train.level_voa)\n",
    "comp_vec_train['near_jaro'] = jarowinkler_similarity(comp_vec_train.near_ldc, comp_vec_train.near_voa)\n",
    "comp_vec_train['postcode_jaro'] = jarowinkler_similarity(comp_vec_train.postcode_ldc, comp_vec_train.postcode_voa)\n",
    "comp_vec_train['state_jaro'] = jarowinkler_similarity(comp_vec_train.state_ldc, comp_vec_train.state_voa)\n",
    "comp_vec_train['state_district_jaro'] = jarowinkler_similarity(comp_vec_train.state_district_ldc, comp_vec_train.state_district_voa)\n",
    "comp_vec_train['suburb_jaro'] = jarowinkler_similarity(comp_vec_train.suburb_ldc, comp_vec_train.suburb_voa)\n",
    "comp_vec_train['unit_jaro'] = jarowinkler_similarity(comp_vec_train.unit_ldc, comp_vec_train.unit_voa)\n",
    "comp_vec_train['tfidf_score'] = tfidf_similarity(comp_vec_train.address_x, comp_vec_train.address_y)\n",
    "\n",
    "# create comparison vector dataframe\n",
    "comp_vec_train[['road_jaro',\n",
    "                'city_jaro',\n",
    "                'city_district_jaro',\n",
    "                'house_jaro',\n",
    "                'house_number_jaro',\n",
    "                'level_jaro',\n",
    "                'near_jaro',\n",
    "                'postcode_jaro',\n",
    "                'state_jaro',\n",
    "                'state_district_jaro',\n",
    "                'suburb_jaro',\n",
    "                'unit_jaro',\n",
    "                'tfidf_score']]\n",
    "\n",
    "# insert match index for identifying matches and non_matches\n",
    "comp_vec_train.insert(0, 'match_index_status', range(0, 0 + len(comp_vec_train)))\n",
    "\n",
    "def is_matched(df):\n",
    "    if df['match_index_status'] < len(comp_vec):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# apply match status \n",
    "comp_vec_train['match_status'] = comp_vec_train.apply(is_matched, axis=1)\n",
    "\n",
    "# use 75% / 25% train:test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_set, test_set = train_test_split(comp_vec_train, test_size = 0.25)\n",
    "\n",
    "# removed features are category, city district, near deduced from feature importance plot (see later)\n",
    "training_set = training_set[['road_jaro',\n",
    "                'city_jaro',\n",
    "                'house_jaro',\n",
    "                'house_number_jaro',\n",
    "                'level_jaro',\n",
    "#                 'postcode_jaro',\n",
    "                'state_jaro',\n",
    "#                 'state_district_jaro',\n",
    "                'suburb_jaro',\n",
    "                'unit_jaro',\n",
    "                'tfidf_score',\n",
    "                'match_status']].fillna('0.0')\n",
    "\n",
    "test_set = test_set[['road_jaro',\n",
    "                'city_jaro',\n",
    "                'house_jaro',\n",
    "                'house_number_jaro',\n",
    "                'level_jaro',\n",
    "#                 'postcode_jaro',\n",
    "                'state_jaro',\n",
    "#                 'state_district_jaro',\n",
    "                'suburb_jaro',\n",
    "                'unit_jaro',\n",
    "                'tfidf_score',\n",
    "                'match_status']].fillna('0.0')\n",
    "\n",
    "# create golden pairs indexes for training all methods\n",
    "golden_matches_index = training_set.drop('match_status',axis=1).index & comp_vec.index \n",
    "\n",
    "############## RANDOM FORESTS ##############\n",
    "\n",
    "# define RF classifier, specifying parameters\n",
    "rfc = RandomForestClassifierRl(trees=1000, features='sqrt') # trees = 1000 , m = sqrt(p)\n",
    "\n",
    "# train rf classifier on training\n",
    "rfc.learn(training_set.drop('match_status',axis=1), golden_matches_index) # drop match status so it is not evalauted\n",
    "\n",
    "# evaluate of testing\n",
    "result_trained_rf = rfc.predict(test_set.drop('match_status',axis=1)) # drop match status so it is not evalauted\n",
    "\n",
    "# get true match indexes for validation\n",
    "true_match_index = test_set[test_set['match_status'] == 1].index\n",
    "\n",
    "# define  size of test set\n",
    "n_pairs = len(test_set)\n",
    "\n",
    "# construct confusion matrix using 'gold matches' from test set and classified links\n",
    "conf_rf = confusion_matrix(true_match_index, result_trained_rf, n_pairs)\n",
    "\n",
    "print('\\033[32m' + 'Random Forests Results: ' + '\\033[0m')\n",
    "print('') #space\n",
    "print(conf_rf)\n",
    "print('') #space\n",
    "print('Recall:   ',recall(conf_rf))\n",
    "print('Precision:',precision(conf_rf))\n",
    "print('F1 Score: ',fscore(conf_rf))\n",
    "print('Specificity: ', specificity(conf_rf))\n",
    "print('False Positive Rate: ', false_positive_rate(conf_rf))\n",
    "print('') #space\n",
    "\n",
    "# retrieve feature importances\n",
    "importances = rfc.feature_importance()\n",
    "\n",
    "#retrieve variance of estiamtor measures\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimator()],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "labels = list(zip(test_set.drop('match_status',axis=1), rfc.feature_importance()))\n",
    "\n",
    "for f in range(test_set.drop('match_status', axis=1).shape[1]):\n",
    "    print(\"%d. %s  (%d) (%f)\" % (f + 1, labels[indices[f]][0], indices[f], importances[indices[f]]))\n",
    "    \n",
    "plt.figure()\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(test_set.drop('match_status', axis=1).shape[1]), \n",
    "        importances[indices],\n",
    "        yerr=std[indices],\n",
    "        color=\"b\", \n",
    "        align=\"center\")\n",
    "plt.xticks(range(test_set.drop('match_status', axis=1).shape[1]), indices)\n",
    "plt.xlim([-1, test_set.drop('match_status', axis=1).shape[1]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "############## XGBOOST ##############\n",
    "\n",
    "xgb = XGBClassifierRl(n_boosted_trees=1000)\n",
    "xgb.learn(training_set.drop('match_status',axis=1), golden_matches_index) #train\n",
    "\n",
    "result_xgb = xgb.predict(test_set.drop('match_status',axis=1)) # test\n",
    "conf_xgb = confusion_matrix(true_match_index, result_xgb, n_pairs) # evaluate\n",
    "\n",
    "print('\\033[32m' + 'XGBoost Results: ' + '\\033[0m')\n",
    "print('') #space\n",
    "print(conf_xgb)\n",
    "print('') #space\n",
    "print('Recall:   ',recall(conf_xgb))\n",
    "print('Precision:',precision(conf_xgb))\n",
    "print('F1 Score: ',fscore(conf_xgb))\n",
    "print('Specificity: ', specificity(conf_xgb))\n",
    "print('False Positive Rate: ', false_positive_rate(conf_xgb))\n",
    "print('') #space\n",
    "\n",
    "############## LOGIT ##############\n",
    "\n",
    "logreg = LogisticRegressionClassifierRl() # define\n",
    "logreg.learn(training_set.drop('match_status',axis=1), golden_matches_index) #train\n",
    "\n",
    "result_logreg = logreg.predict(test_set.drop('match_status',axis=1)) # test\n",
    "conf_log = confusion_matrix(true_match_index, result_logreg, n_pairs) # evaluate\n",
    "\n",
    "print('\\033[32m' + 'Logistic Regression Results:' + '\\033[0m')\n",
    "print('') #space\n",
    "print(conf_log)\n",
    "print('') #space\n",
    "print('Recall:   ',recall(conf_log))\n",
    "print('Precision:',precision(conf_log))\n",
    "print('F1 Score: ',fscore(conf_log))\n",
    "print('Specificity: ', specificity(conf_log))\n",
    "print('False Positive Rate: ', false_positive_rate(conf_log))\n",
    "print('') #space\n",
    "\n",
    "############# ROC CURVES ############\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [logreg, rfc]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    name = repr(model).split(' ')[0].split('.')[1]\n",
    "    \n",
    "    print('')\n",
    "    print('\\033[32m' + name + '\\033[0m')\n",
    "    print('')\n",
    "\n",
    "    # true labels\n",
    "    y_pred = model.predict_proba(test_set.drop('match_status',axis=1))[:, 1]\n",
    "    \n",
    "    # probabilities estiamtes for classes\n",
    "    y_test = np.asarray(test_set['match_status'].tolist())\n",
    "\n",
    "    # define ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "    # area under curve parameterised by false positive rate and true positive rate\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature correlation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 9 elements, new values have 11 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b7ec3caf742f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m test.columns = ['road', 'city', 'house', 'house_number',\n\u001b[1;32m      6\u001b[0m        \u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state_district'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'suburb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m        'unit', 'tfidf', 'match_status']\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2758\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/properties.pyx\u001b[0m in \u001b[0;36mpandas.lib.AxisProperty.__set__ (pandas/lib.c:46249)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   2800\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[1;32m   2801\u001b[0m                              \u001b[0;34m'new values have %d elements'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2802\u001b[0;31m                              (old_len, new_len))\n\u001b[0m\u001b[1;32m   2803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2804\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 9 elements, new values have 11 elements"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test = test_set.drop('match_status',axis=1).reset_index(drop=1)\n",
    "\n",
    "test.columns = ['road', 'city', 'house', 'house_number',\n",
    "       'level', 'state', 'state_district', 'suburb',\n",
    "       'unit', 'tfidf']\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = test.astype(float).corr()\n",
    "sns.heatmap(corr, cmap='RdBu_r')\n",
    "\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random forest variance estimates</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forestci as fci\n",
    "from sklearn.ensemble.forest import _generate_sample_indices\n",
    "\n",
    "# set number of trees\n",
    "n_trees = 1000\n",
    "\n",
    "# compute rf error\n",
    "rfc_unbiased = random_forest_error(rfc,\n",
    "                                   train, \n",
    "                                   test,\n",
    "                                   n_trees)\n",
    "\n",
    "# get predicted values\n",
    "pred_y_hat = rfc.predict_proba(test_set.drop('match_status',axis=1))\n",
    "\n",
    "# plot for matches and non-matches\n",
    "idx = np.where(test_set['match_status'] == 1)[0]\n",
    "plt.errorbar(pred_y_hat[idx, 1], np.sqrt(rfc_unbiased[idx]), \n",
    "             fmt='.', alpha=0.50, label='Match',c='green')\n",
    "\n",
    "idx = np.where(test_set['match_status'] == 0)[0]\n",
    "plt.errorbar(pred_y_hat[idx, 1], np.sqrt(rfc_unbiased[idx]), \n",
    "             fmt='.',c='red',alpha=0.50, label='Non-match')\n",
    "\n",
    "plt.xlabel('Prediction (match probability)')\n",
    "plt.ylabel('Standard deviation')\n",
    "plt.legend(loc=2, prop={'size':11})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature space demonstration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training data equal to only 2 features so can show on 2-D plot\n",
    "training = training_set[['house_number_jaro','tfidf_score']]\n",
    "\n",
    "# train\n",
    "rfc.learn(training, golden_matches_index) #train\n",
    "\n",
    "# create grid of values\n",
    "xx, yy = np.mgrid[0:1.1:0.1 ,0:1.1:0.1]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# predict probabilies \n",
    "probs = rfc.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# set features\n",
    "X = test_set[['house_number_jaro', 'tfidf_score']].as_matrix()[0:20000]\n",
    "y = test_set['match_status'].as_matrix()[0:20000]\n",
    "\n",
    "# define shape of boundary\n",
    "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
    "                      vmin=0, vmax=1)\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "ax.scatter(X[:,0], X[:,1], c=y,s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlim=(0, 1), ylim=(0, 1),\n",
    "       xlabel=\"$X_1$\", ylabel=\"$X_2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Propensity Score Matching with Word Embeddings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load training data\n",
    "ldc_training, voa_training, all_address_train = all_addresses(training=True, word2vec=True)\n",
    "\n",
    "# create corpus of documents (addresses)\n",
    "docs = all_address_train\n",
    "documents = [doc.split() for doc in docs]\n",
    "dictionary = Dictionary(documents)\n",
    "\n",
    "# create tfidf model \n",
    "tfidf_model = TfidfModel([dictionary.doc2bow(d) for d in documents], id2word=dictionary)\n",
    "\n",
    "# create count for each word\n",
    "results = Counter()\n",
    "all_address_train.str.split().apply(results.update)\n",
    "\n",
    "# create word frequencies for candidate search and replace values\n",
    "frequency_table = dict(results.most_common())\n",
    "\n",
    "total_terms = sum(frequency_table.values())\n",
    "total_documents = len(all_address_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-24 16:01:43,525 : INFO : running /home/sam/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py -f /run/user/1000/jupyter/kernel-e2e3cd65-6ed0-4450-b6e0-083efbc38c20.json\n",
      "2017-08-24 16:01:43,528 : INFO : collecting all words and their counts\n",
      "2017-08-24 16:01:43,529 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-08-24 16:01:43,608 : INFO : PROGRESS: at sentence #10000, processed 71908 words, keeping 13656 word types\n",
      "2017-08-24 16:01:43,670 : INFO : PROGRESS: at sentence #20000, processed 148295 words, keeping 25845 word types\n",
      "2017-08-24 16:01:43,726 : INFO : PROGRESS: at sentence #30000, processed 224661 words, keeping 37363 word types\n",
      "2017-08-24 16:01:43,781 : INFO : PROGRESS: at sentence #40000, processed 297535 words, keeping 48716 word types\n",
      "2017-08-24 16:01:43,837 : INFO : PROGRESS: at sentence #50000, processed 374183 words, keeping 59839 word types\n",
      "2017-08-24 16:01:43,893 : INFO : PROGRESS: at sentence #60000, processed 449193 words, keeping 70984 word types\n",
      "2017-08-24 16:01:43,947 : INFO : PROGRESS: at sentence #70000, processed 520885 words, keeping 81847 word types\n",
      "2017-08-24 16:01:44,004 : INFO : PROGRESS: at sentence #80000, processed 592628 words, keeping 92711 word types\n",
      "2017-08-24 16:01:44,061 : INFO : PROGRESS: at sentence #90000, processed 670095 words, keeping 103733 word types\n",
      "2017-08-24 16:01:44,118 : INFO : PROGRESS: at sentence #100000, processed 743824 words, keeping 114535 word types\n",
      "2017-08-24 16:01:44,184 : INFO : PROGRESS: at sentence #110000, processed 841558 words, keeping 126104 word types\n",
      "2017-08-24 16:01:44,263 : INFO : PROGRESS: at sentence #120000, processed 954783 words, keeping 137137 word types\n",
      "2017-08-24 16:01:44,335 : INFO : PROGRESS: at sentence #130000, processed 1071038 words, keeping 148239 word types\n",
      "2017-08-24 16:01:44,398 : INFO : PROGRESS: at sentence #140000, processed 1185291 words, keeping 159275 word types\n",
      "2017-08-24 16:01:44,461 : INFO : PROGRESS: at sentence #150000, processed 1304880 words, keeping 169979 word types\n",
      "2017-08-24 16:01:44,525 : INFO : PROGRESS: at sentence #160000, processed 1420817 words, keeping 180967 word types\n",
      "2017-08-24 16:01:44,586 : INFO : PROGRESS: at sentence #170000, processed 1533251 words, keeping 191755 word types\n",
      "2017-08-24 16:01:44,647 : INFO : PROGRESS: at sentence #180000, processed 1644077 words, keeping 202647 word types\n",
      "2017-08-24 16:01:44,707 : INFO : PROGRESS: at sentence #190000, processed 1756474 words, keeping 213592 word types\n",
      "2017-08-24 16:01:44,769 : INFO : PROGRESS: at sentence #200000, processed 1869420 words, keeping 224507 word types\n",
      "2017-08-24 16:01:44,830 : INFO : PROGRESS: at sentence #210000, processed 1983648 words, keeping 235332 word types\n",
      "2017-08-24 16:01:44,863 : INFO : collected 240677 word types from a corpus of 2041825 raw words and 214962 sentences\n",
      "2017-08-24 16:01:44,864 : INFO : Loading a fresh vocabulary\n",
      "2017-08-24 16:01:45,590 : INFO : min_count=0 retains 240677 unique words (100% of original 240677, drops 0)\n",
      "2017-08-24 16:01:45,591 : INFO : min_count=0 leaves 2041825 word corpus (100% of original 2041825, drops 0)\n",
      "2017-08-24 16:01:46,192 : INFO : deleting the raw counts dictionary of 240677 items\n",
      "2017-08-24 16:01:46,196 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2017-08-24 16:01:46,198 : INFO : downsampling leaves estimated 1676642 word corpus (82.1% of prior 2041825)\n",
      "2017-08-24 16:01:46,199 : INFO : estimated required memory for 240677 words and 100 dimensions: 312880100 bytes\n",
      "2017-08-24 16:01:47,015 : INFO : resetting layer weights\n",
      "2017-08-24 16:01:49,815 : INFO : training model with 28 workers on 240677 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-08-24 16:01:49,817 : INFO : expecting 214962 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-08-24 16:01:50,945 : INFO : PROGRESS: at 1.48% examples, 95800 words/s, in_qsize 53, out_qsize 2\n",
      "2017-08-24 16:01:51,980 : INFO : PROGRESS: at 9.46% examples, 312694 words/s, in_qsize 55, out_qsize 0\n",
      "2017-08-24 16:01:52,996 : INFO : PROGRESS: at 13.60% examples, 336527 words/s, in_qsize 56, out_qsize 1\n",
      "2017-08-24 16:01:54,000 : INFO : PROGRESS: at 17.53% examples, 345349 words/s, in_qsize 56, out_qsize 1\n",
      "2017-08-24 16:01:55,038 : INFO : PROGRESS: at 21.96% examples, 348704 words/s, in_qsize 54, out_qsize 1\n",
      "2017-08-24 16:01:56,081 : INFO : PROGRESS: at 29.13% examples, 372199 words/s, in_qsize 54, out_qsize 1\n",
      "2017-08-24 16:01:57,094 : INFO : PROGRESS: at 33.59% examples, 377110 words/s, in_qsize 56, out_qsize 0\n",
      "2017-08-24 16:01:58,102 : INFO : PROGRESS: at 36.18% examples, 361479 words/s, in_qsize 56, out_qsize 1\n",
      "2017-08-24 16:01:59,111 : INFO : PROGRESS: at 41.00% examples, 368448 words/s, in_qsize 55, out_qsize 0\n",
      "2017-08-24 16:02:00,123 : INFO : PROGRESS: at 47.29% examples, 376020 words/s, in_qsize 53, out_qsize 2\n",
      "2017-08-24 16:02:01,185 : INFO : PROGRESS: at 52.76% examples, 381848 words/s, in_qsize 49, out_qsize 6\n",
      "2017-08-24 16:02:02,185 : INFO : PROGRESS: at 55.58% examples, 373107 words/s, in_qsize 55, out_qsize 0\n",
      "2017-08-24 16:02:03,210 : INFO : PROGRESS: at 60.73% examples, 379433 words/s, in_qsize 54, out_qsize 1\n",
      "2017-08-24 16:02:04,231 : INFO : PROGRESS: at 67.77% examples, 387454 words/s, in_qsize 55, out_qsize 1\n",
      "2017-08-24 16:02:05,242 : INFO : PROGRESS: at 71.95% examples, 384845 words/s, in_qsize 55, out_qsize 0\n",
      "2017-08-24 16:02:06,251 : INFO : PROGRESS: at 75.80% examples, 384125 words/s, in_qsize 54, out_qsize 1\n",
      "2017-08-24 16:02:07,263 : INFO : PROGRESS: at 80.41% examples, 385837 words/s, in_qsize 55, out_qsize 1\n",
      "2017-08-24 16:02:08,295 : INFO : PROGRESS: at 85.62% examples, 384725 words/s, in_qsize 54, out_qsize 1\n",
      "2017-08-24 16:02:09,345 : INFO : PROGRESS: at 91.67% examples, 388568 words/s, in_qsize 56, out_qsize 0\n",
      "2017-08-24 16:02:10,197 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2017-08-24 16:02:10,226 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2017-08-24 16:02:10,236 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2017-08-24 16:02:10,258 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2017-08-24 16:02:10,261 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2017-08-24 16:02:10,280 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2017-08-24 16:02:10,300 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2017-08-24 16:02:10,306 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2017-08-24 16:02:10,330 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-08-24 16:02:10,335 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-08-24 16:02:10,342 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2017-08-24 16:02:10,357 : INFO : PROGRESS: at 98.76% examples, 402461 words/s, in_qsize 8, out_qsize 17\n",
      "2017-08-24 16:02:10,363 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-08-24 16:02:10,365 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-08-24 16:02:10,367 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-08-24 16:02:10,369 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-08-24 16:02:10,370 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-08-24 16:02:10,371 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-08-24 16:02:10,373 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-08-24 16:02:10,374 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-08-24 16:02:10,375 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-08-24 16:02:10,376 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-08-24 16:02:10,377 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-08-24 16:02:10,378 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-08-24 16:02:10,381 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-08-24 16:02:10,382 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-08-24 16:02:10,383 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-08-24 16:02:10,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-08-24 16:02:10,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-08-24 16:02:10,387 : INFO : training on 10209125 raw words (8383106 effective words) took 20.6s, 407726 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# training quick word2vec model\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    program = os.path.basename(sys.argv[0])\n",
    "    logger = logging.getLogger(program)\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "    logging.root.setLevel(level=logging.INFO)\n",
    "    logger.info(\"running %s\" % ' '.join(sys.argv))\n",
    "    \n",
    "    model = Word2Vec(LineSentence('./data/all_address_train.csv'),  # paf_and_ldcvoa all_address_train\n",
    "                     size=100, # dimensionality of feature vectors\n",
    "                     window=5, # distance between current and predicted word\n",
    "                     min_count=0, # ignore words with total frequency\n",
    "                     workers=multiprocessing.cpu_count(), # set no cores\n",
    "                     sg=0, # CBOW = 0, SKIP-GRAM = 1\n",
    "                     hs=0 # negative sampling = 0, hierarchical softmax = 1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-24 16:02:23,304 : INFO : loading Word2Vec object from ./models/w2v_addresses_training\n",
      "2017-08-24 16:02:24,007 : INFO : loading wv recursively from ./models/w2v_addresses_training.wv.* with mmap=None\n",
      "2017-08-24 16:02:24,008 : INFO : loading syn0 from ./models/w2v_addresses_training.wv.syn0.npy with mmap=None\n",
      "2017-08-24 16:02:24,196 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-08-24 16:02:24,198 : INFO : loading syn1neg from ./models/w2v_addresses_training.syn1neg.npy with mmap=None\n",
      "2017-08-24 16:02:24,391 : INFO : setting ignored attribute cum_table to None\n",
      "2017-08-24 16:02:24,393 : INFO : loaded ./models/w2v_addresses_training\n"
     ]
    }
   ],
   "source": [
    "# load quick w2v model \n",
    "\n",
    "# for LDC + VOA (CBOW), use w2v_addresses_training (100 dimensions)\n",
    "paf_w2v = gensim.models.Word2Vec.load('./models/w2v_addresses_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create labels for splitting appended file into voa/ldc\n",
    "ldc_training['status'] = 1\n",
    "voa_training['status'] = 0\n",
    "\n",
    "# append voa and ldc train data\n",
    "training = ldc_training.append(voa_training)\n",
    "\n",
    "# construct 75 / 25 training, test set split\n",
    "training_set_psm, test_set_psm = train_test_split(training, test_size = 0.25)\n",
    "\n",
    "# use labels to split by ldc/voa for generating feature vectors for each\n",
    "ldc_training_ = training_set_psm[training_set_psm['status'] == 1]\n",
    "voa_training_ = training_set_psm[training_set_psm['status'] == 0]\n",
    "\n",
    "# test whether to use tfidf or inverse weighting\n",
    "tfidf = True\n",
    "\n",
    "if tfidf == True:\n",
    "\n",
    "    # get dimensions with tfidf from training data\n",
    "    def joblib_loop(data):\n",
    "        return Parallel(n_jobs=20)(delayed(avg_feature_vector)(words=address.split()) for i,address in enumerate(data))\n",
    "\n",
    "    avg_training_vectors_ldc_tfidf = joblib_loop(ldc_training_['address']) # ldc\n",
    "    avg_training_vectors_voa_tfidf = joblib_loop(voa_training_['address']) # voa\n",
    "\n",
    "else:\n",
    "    \n",
    "    # get dimensions with inverse weighting of words from training data\n",
    "    def joblib_loop(data):\n",
    "        return Parallel(n_jobs=20)(delayed(avg_feature_vector)(words=address.split(), weight_avg=True) for i,address in enumerate(data))\n",
    "\n",
    "    avg_training_vectors_ldc_iw = joblib_loop(ldc_training_['address']) # ldc\n",
    "    avg_training_vectors_voa_iw = joblib_loop(voa_training_['address']) # voa\n",
    "\n",
    "########### TRAINING ###########\n",
    "\n",
    "# generate X for training\n",
    "X_train = np.asarray(avg_training_vectors_ldc_tfidf + avg_training_vectors_voa_tfidf)\n",
    "\n",
    "# create ldc/voa labels\n",
    "treated = np.ones(len(avg_training_vectors_ldc_tfidf))\n",
    "untreated = np.zeros(len(avg_training_vectors_voa_tfidf))\n",
    "\n",
    "# assign labels as Y\n",
    "y = np.concatenate([treated, untreated])\n",
    "\n",
    "# train logistic regression on training set\n",
    "propensity = LogisticRegression()\n",
    "propensity = propensity.fit(X_train, y)\n",
    "\n",
    "# train random forests on training set\n",
    "propensity_rf = RandomForestClassifier()\n",
    "propensity_rf = propensity_rf.fit(X_train, y)\n",
    "\n",
    "########### TESTING ###########\n",
    "\n",
    "# use labels to split by ldc/voa for generating feature vectors for each\n",
    "ldc_testing_ = test_set_psm[test_set_psm['status'] == 1]\n",
    "voa_testing_ = test_set_psm[test_set_psm['status'] == 0]\n",
    "\n",
    "# ensure same length for testing\n",
    "ldc_testing_ = ldc_testing_[0:len(voa_testing_)]\n",
    "\n",
    "# get feature vecs for testing\n",
    "avg_testing_vecs_ldc = joblib_loop(ldc_testing_['address']) # ldc\n",
    "avg_testing_vecs_voa = joblib_loop(voa_testing_['address']) # voa\n",
    "\n",
    "# generate X vectors for testing data\n",
    "X_test = np.asarray(avg_testing_vecs_ldc + avg_testing_vecs_voa)\n",
    "\n",
    "# get pscores for test set\n",
    "pscore = propensity_rf.predict_proba(X_test)[:,1]\n",
    "propensity_scores = pd.Series(pscore) # index preserved so we can match back to rows\n",
    "\n",
    "# create labels for ldc/voa\n",
    "treated = np.ones(len(avg_testing_vecs_ldc))\n",
    "untreated = np.zeros(len(avg_testing_vecs_voa))\n",
    "\n",
    "# assign labels to Y\n",
    "y = np.concatenate([treated, untreated])\n",
    "\n",
    "# obtain propensity scores\n",
    "matched = matching(y, propensity_scores)\n",
    "N = len(y)\n",
    "N1 = int(y.sum())\n",
    "N2 = N - N1\n",
    "\n",
    "# retrieve propensity scores for g1 (ldc) and g2 (voa)\n",
    "g1, g2 = propensity_scores[0:N1], propensity_scores[N1:]\n",
    "\n",
    "# matched output\n",
    "out = list(zip(g1.index, g1, g2[matched], g2[matched].index))\n",
    "\n",
    "# here we reset indexes so that pscores can be joined to testing data\n",
    "ldc_testing_ = ldc_testing_.reset_index()\n",
    "\n",
    "voa_testing_['reindex'] = g2.index\n",
    "voa_testing_ = voa_testing_.set_index('reindex')\n",
    "\n",
    "# create list of matched tuples based on indexes\n",
    "matches = [(v[0], v[3]) for v in out]\n",
    "\n",
    "# generate separate list for ldc and voa indexes (these lists are same size)\n",
    "ldc_index, voa_index = [x[0] for x in matches], [x[1] for x in matches]\n",
    "\n",
    "# zip together using indexes \n",
    "classified_matches = list(zip(ldc_testing_.loc[ldc_index].index, voa_testing_.loc[voa_index].index))\n",
    "\n",
    "# build df for pscore and address\n",
    "ldc, voa = [v[0:2] for v in out], [v[2:4] for v in out]\n",
    "\n",
    "# append pscores to dataframes\n",
    "ldc_psm, voa_psm = pd.DataFrame(ldc, columns=['index', 'pscore_ldc']), pd.DataFrame(voa, columns=['pscore_voa', 'index'])\n",
    "ldc_psm, voa_psm = pd.merge(ldc_psm, ldc_testing_, \n",
    "                            left_on='index', \n",
    "                            right_index=True, \n",
    "                            how='left'), pd.merge(voa_psm, \n",
    "                                                  voa_testing_, \n",
    "                                                  left_on='index', \n",
    "                                                  right_index=True, \n",
    "                                                  how='left')\n",
    "\n",
    "# set uarn as index for matching\n",
    "# voa_testing_ = voa_testing_.set_index('uarn')\n",
    "\n",
    "# get indexes of classified amtches\n",
    "ldc_ind, voa_ind = [i[0] for i in classified_matches], [i[1] for i in classified_matches]\n",
    "\n",
    "# get multi index df from test set\n",
    "mask = test_set_psm.uarn.duplicated(keep=False)\n",
    "\n",
    "# keep rows with uarn record\n",
    "match_uarns = test_set_psm[mask].uarn.tolist()\n",
    "\n",
    "# get gold standard of 100% matched (same size as testing set)\n",
    "ldc_uarns = ldc_training[ldc_training['uarn'].isin(match_uarns)]\n",
    "voa_uarns = voa_training[voa_training['uarn'].isin(match_uarns)]\n",
    "\n",
    "# merge based on UARN key to generate golden pairs\n",
    "golden_pairs = ldc_uarns.merge(voa_uarns, on='uarn').set_index([ldc_uarns.index, 'uarn'])\n",
    "golden_pairs.index.names = ['ldc', 'voa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPSM-WORD2VEC (NO BLOCKING) results: \u001b[0m\n",
      "\n",
      "[[    0  8941]\n",
      " [26067 18733]]\n",
      "\n",
      "Recall:    0.0\n",
      "Precision: 0.0\n",
      "Specificity:  0.4181473214285714\n",
      "False Positive Rate:  0.5818526785714285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########### PSM-WORD2VEC WITH NO BLOCKING ##########\n",
    "\n",
    "# ldc keys use id whereas voa keys use uarn for indexing\n",
    "first_psm = pd.merge(ldc_testing_.loc[ldc_ind], voa_testing_.loc[voa_ind].reset_index(), left_index=True, right_index=True)\n",
    "\n",
    "first_psm = first_psm.set_index(['index', 'uarn_y'])\n",
    "\n",
    "first_psm.index.names = ['ldc', 'voa']\n",
    "\n",
    "conf_psm_non_block = confusion_matrix(golden_pairs.index, first_psm.index, len(test_set_psm))\n",
    "\n",
    "print('\\033[32m' + 'PSM-WORD2VEC (NO BLOCKING) results: ' + '\\033[0m')\n",
    "print('')\n",
    "print(conf_psm_non_block)\n",
    "print('')\n",
    "print('Recall:   ', recall(conf_psm_non_block))\n",
    "print('Precision:', precision(conf_psm_non_block))\n",
    "# print('F1 Score: ', fscore(conf_psm_non_block))\n",
    "print('Specificity: ', specificity(conf_psm_non_block))\n",
    "print('False Positive Rate: ', false_positive_rate(conf_psm_non_block))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPSM-WORD2VEC with blocking results: \u001b[0m\n",
      "\n",
      "[[   29  8912]\n",
      " [15065 29735]]\n",
      "\n",
      "Recall:    0.003243485068784252\n",
      "Precision: 0.0019212932290976546\n",
      "F1 Score:  0.0024131474932390265\n",
      "Specificity:  0.6637276785714286\n",
      "False Positive Rate:  0.33627232142857144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######### PSM-WORD2VEC WITH BLOCKING ##############\n",
    "\n",
    "# rename column due to odd keyvalue error in blocking function\n",
    "ldc_psm.rename(columns={'index_y':'ldc_ind'}, inplace=True)\n",
    "\n",
    "# block by postcode\n",
    "pc_dict_psm = postcode_block(ldc_psm[['postcode', 'pscore_ldc', 'ldc_ind']], voa_psm,  'postcode')\n",
    "\n",
    "# create dict of postcode dataframes\n",
    "dict_pc = {k:v for k,v in pc_dict_psm.groupby('postcode')}\n",
    "\n",
    "def blocked_psm_score(block):\n",
    "\n",
    "    voa = block.index.get_level_values(1)\n",
    "\n",
    "    pscores_ = voa_psm['pscore_voa'].loc[voa].tolist()\n",
    "\n",
    "    block['pscore_voa'] = pscores_\n",
    "        \n",
    "    return block\n",
    "\n",
    "def joblib_loop():\n",
    "    return Parallel(n_jobs=28)(delayed(blocked_psm_score)(block) for pc, block in dict_pc.items())\n",
    "\n",
    "# parallelise \n",
    "dict_pc_pscores = joblib_loop()\n",
    "\n",
    "# define list to append blocked dataframes to\n",
    "master_psm_df = []\n",
    "\n",
    "# for each LDC row, return nearest neighbour propensity score\n",
    "def create_blocked_psm_df(i):\n",
    "\n",
    "    ldc = ldc_psm.loc[i.index.get_level_values(0).unique()]\n",
    "    voa = voa_psm.loc[i.index.get_level_values(1).unique()]\n",
    "\n",
    "    # retrieve propensity scores for each LDC and VOA record\n",
    "    g1, g2 = pd.Series(ldc['pscore_ldc'].tolist()), pd.Series(voa['pscore_voa'].tolist())\n",
    "\n",
    "    N = len(i)\n",
    "    N1 = len(g1)\n",
    "    N2 = N - N1\n",
    "\n",
    "    morder = np.random.permutation(N1)\n",
    "    matches = pd.Series(np.empty(N1))\n",
    "    matches[:] = np.NAN\n",
    "\n",
    "    # matching with replacement\n",
    "    for m in morder:\n",
    "        dist = abs(g1[m] - g2)\n",
    "        matches[m] = dist.argmin()\n",
    "\n",
    "    index_to_id = [voa['index'].tolist()[int(matches.values[i])] for i in range(len(matches))]\n",
    "\n",
    "    # retrieve index of smallest propensity score distance\n",
    "    ldc['smallest_psm_dist'] = pd.Series(index_to_id).values   \n",
    "    \n",
    "    # reset both indexes so they can be appended back \n",
    "    ldc = ldc.reset_index(drop=True) \n",
    "    voa = voa.reset_index(drop=True)\n",
    "\n",
    "    psm_out = pd.merge(ldc, voa, left_index=True, right_index=True)\n",
    "    psm_out = psm_out.set_index(['ldc_ind', 'uarn_y'])\n",
    "    psm_out.index.names = ['ldc', 'voa'] # set index names so can match to ground truth\n",
    "                \n",
    "    return psm_out\n",
    "        \n",
    "def blocked_psm_paralellised():\n",
    "    return Parallel(n_jobs=28)(delayed(create_blocked_psm_df)(i) for i in dict_pc_pscores)\n",
    "\n",
    "master_psm_df = blocked_psm_paralellised()\n",
    "\n",
    "# flatten to single dataframe\n",
    "blocked_psm = pd.concat(master_psm_df, axis=0)\n",
    "\n",
    "# evaluate \n",
    "conf_psm_block = confusion_matrix(golden_pairs.index, blocked_psm.index, len(test_set_psm))\n",
    "\n",
    "print('\\033[32m' + 'PSM-WORD2VEC with blocking results: ' + '\\033[0m')\n",
    "print('')\n",
    "print(conf_psm_block)\n",
    "print('')\n",
    "print('Recall:   ', recall(conf_psm_block))\n",
    "print('Precision:', precision(conf_psm_block))\n",
    "print('F1 Score: ', fscore(conf_psm_block))\n",
    "print('Specificity: ', specificity(conf_psm_block))\n",
    "print('False Positive Rate: ', false_positive_rate(conf_psm_block))\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
